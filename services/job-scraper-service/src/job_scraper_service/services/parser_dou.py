import requests
from bs4 import BeautifulSoup
import time
from typing import List, Dict


def get_dou_vacancies(
    search_query: str,
    max_vacancies: int = 20,
    delay: float = 0.5,
    desc_length: int = 500,  # üëà –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –æ–ø–∏—Å–∞–Ω–∏—è
) -> List[Dict]:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –≤–∞–∫–∞–Ω—Å–∏–∏ —Å —Å–∞–π—Ç–∞ DOU.ua –ø–æ –ø–æ–∏—Å–∫–æ–≤–æ–º—É –∑–∞–ø—Ä–æ—Å—É.

    Args:
        search_query (str): –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å.
        max_vacancies (int): –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞–∫–∞–Ω—Å–∏–π –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞.
        delay (float): –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ –∫ —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º –≤–∞–∫–∞–Ω—Å–∏–π.
        desc_length (int): –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞ –æ–ø–∏—Å–∞–Ω–∏—è (–≤ —Å–∏–º–≤–æ–ª–∞—Ö).

    Returns:
        list of dict: —Å–ø–∏—Å–æ–∫ –≤–∞–∫–∞–Ω—Å–∏–π —Å –ø–æ–ª—è–º–∏ title, company, city, salary, link, description.
    """
    base_url = "https://jobs.dou.ua/vacancies/"
    headers = {"User-Agent": "Mozilla/5.0"}

    response = requests.get(
        f"{base_url}?search={search_query.replace(' ', '+')}", headers=headers
    )
    soup = BeautifulSoup(response.text, "html.parser")

    vacancies = soup.select("li.l-vacancy")
    results = []

    for vac in vacancies[:max_vacancies]:
        title_tag = vac.select_one("a.vt")
        company_tag = vac.select_one("a.company")
        city_tag = vac.select_one("span.cities")
        salary_tag = vac.select_one("span.salary")

        title = title_tag.text.strip() if title_tag else "-"
        link = title_tag["href"] if title_tag else "-"
        company = company_tag.text.strip() if company_tag else "-"
        city = city_tag.text.strip() if city_tag else "-"
        salary = salary_tag.text.strip() if salary_tag else "-"

        # --- –ü–æ–ª—É—á–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏ ---
        description = "-"
        if link != "-":
            try:
                vac_response = requests.get(link, headers=headers, timeout=10)
                vac_soup = BeautifulSoup(vac_response.text, "html.parser")
                desc_tag = vac_soup.select_one("div.vacancy-section")
                if desc_tag:
                    full_text = desc_tag.get_text(separator="\n").strip()
                    # –û–±—Ä–µ–∑–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ, –µ—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ
                    description = (
                        (full_text[:desc_length] + "...")
                        if len(full_text) > desc_length
                        else full_text
                    )
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –æ–ø–∏—Å–∞–Ω–∏—è {link}: {e}")
            time.sleep(delay)

        results.append(
            {
                "title": title,
                "company": company,
                "location": city,
                "salary": salary,
                "link": link,
                "description": description,
            }
        )

    return results
